# ðŸ¤— Hugging Face Integration Guide

Guia completo para deploy e integraÃ§Ã£o do JurDatasetBrasil com Hugging Face Hub e Spaces.

---

## ðŸ“‹ Ãndice

1. [Setup Inicial](#setup-inicial)
2. [Deploy do Space](#deploy-do-space)
3. [Upload do Dataset](#upload-do-dataset)
4. [CI/CD AutomÃ¡tico](#cicd-automÃ¡tico)
5. [Troubleshooting](#troubleshooting)

---

## ðŸš€ Setup Inicial

### 1. Criar Conta no Hugging Face

1. Acesse [huggingface.co](https://huggingface.co)
2. Crie uma conta gratuita
3. VÃ¡ em **Settings â†’ Access Tokens**
4. Crie um token com permissÃµes `write`

### 2. Configurar Token Localmente

```bash
# Instalar Hugging Face CLI
pip install huggingface-hub

# Login
huggingface-cli login
# Cole seu token quando solicitado
```

### 3. Adicionar Token ao GitHub

1. VÃ¡ em **Settings â†’ Secrets and variables â†’ Actions**
2. Crie um secret chamado `HF_TOKEN`
3. Cole seu token do Hugging Face

---

## ðŸŒ Deploy do Space

### OpÃ§Ã£o 1: Deploy Manual

```bash
# 1. Criar Space no HF
# Acesse: https://huggingface.co/new-space
# Nome: JurDatasetBrasil-Explorer
# SDK: Gradio
# Hardware: CPU basic

# 2. Clone o Space localmente
git clone https://huggingface.co/spaces/prof-ramos/JurDatasetBrasil-Explorer
cd JurDatasetBrasil-Explorer

# 3. Copiar arquivos
cp ../huggingface/app.py app.py
cp ../.space.yml .
cp ../requirements-huggingface.txt requirements.txt
cp ../huggingface/README.md README.md

# 4. Commit e push
git add .
git commit -m "Initial commit"
git push
```

### OpÃ§Ã£o 2: Deploy AutomÃ¡tico via GitHub Actions

O projeto jÃ¡ inclui workflow automÃ¡tico (`.github/workflows/sync-huggingface.yml`):

**Triggers automÃ¡ticos:**
- Push para `main` que modifica arquivos em `huggingface/`
- Push para `main` que modifica `3-FinalDataset/`

**Trigger manual:**
```bash
# Via GitHub UI: Actions â†’ Sync to Hugging Face â†’ Run workflow
```

---

## ðŸ“Š Upload do Dataset

### Upload Manual

```bash
# 1. Preparar dataset (exportar para JSONL)
python scripts/05_export_to_jsonl.py

# 2. Verificar arquivos
ls -lh 3-FinalDataset/*.jsonl

# 3. Upload
python huggingface/upload_dataset.py
```

**VariÃ¡veis de ambiente:**
```bash
export HF_TOKEN="hf_..."
export HF_REPO_ID="prof-ramos/JurDatasetBrasil"
python huggingface/upload_dataset.py
```

### Upload AutomÃ¡tico via GitHub Actions

```bash
# Trigger manual do workflow
gh workflow run sync-huggingface.yml \
  -f upload_dataset=true \
  -f sync_space=true
```

---

## ðŸ”„ CI/CD AutomÃ¡tico

### Workflow: `sync-huggingface.yml`

O workflow possui 3 jobs:

#### 1. **sync-space**
- Roda em: push para `main` ou trigger manual
- Sincroniza cÃ³digo do Space
- Copia: `app.py`, `.space.yml`, `requirements.txt`, `README.md`

#### 2. **upload-dataset**
- Roda em: trigger manual com flag `upload_dataset=true`
- Valida arquivos JSONL em `3-FinalDataset/`
- Faz upload para HF Hub
- Cria tag de release

#### 3. **notify**
- Roda apÃ³s completion dos outros jobs
- Gera resumo no GitHub Actions

### Exemplo de Uso

```bash
# 1. Gerar dataset
python scripts/run_pipeline.py

# 2. Commit e push
git add 3-FinalDataset/
git commit -m "feat: adicionar novos exemplos do dataset"
git push origin main

# 3. Trigger upload manual (se necessÃ¡rio)
gh workflow run sync-huggingface.yml -f upload_dataset=true
```

---

## ðŸ³ Docker para HF Spaces

O projeto inclui `Dockerfile.huggingface` otimizado:

### Features

- âœ… Base: `python:3.11-slim`
- âœ… UsuÃ¡rio nÃ£o-root (requerido pelo HF)
- âœ… Cache de modelos em `/app/.cache`
- âœ… Suporte a GPU (opcional)
- âœ… Healthcheck integrado

### Build Local

```bash
# Build
docker build -f Dockerfile.huggingface -t jurdataset-hf:latest .

# Run
docker run -p 7860:7860 \
  -e HF_TOKEN=$HF_TOKEN \
  -e DATASET_NAME=prof-ramos/JurDatasetBrasil \
  jurdataset-hf:latest

# Acessar
open http://localhost:7860
```

---

## ðŸ“¦ Estrutura de Arquivos HF

```
JurDatasetBrasil/
â”œâ”€â”€ huggingface/
â”‚   â”œâ”€â”€ app.py                    # Gradio app principal
â”‚   â”œâ”€â”€ upload_dataset.py         # Script de upload
â”‚   â””â”€â”€ README.md                 # Dataset card (HF Hub)
â”œâ”€â”€ .space.yml                    # Config do Space
â”œâ”€â”€ Dockerfile.huggingface        # Docker otimizado
â”œâ”€â”€ requirements-huggingface.txt  # Deps adicionais
â””â”€â”€ .github/workflows/
    â””â”€â”€ sync-huggingface.yml      # CI/CD workflow
```

---

## ðŸŽ¨ CustomizaÃ§Ã£o do Space

### Modificar Interface

Edite `huggingface/app.py`:

```python
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    # Adicione tabs, components, etc.
    with gr.Tab("ðŸ” Nova Funcionalidade"):
        # Seu cÃ³digo aqui
        pass
```

### Adicionar Hardware GPU

1. No HF Space Settings
2. Hardware â†’ Upgrade to GPU
3. OpÃ§Ãµes: T4 ($0.60/h), A10G ($3.15/h), A100 ($4.13/h)

### VariÃ¡veis de Ambiente

Adicione em Settings â†’ Variables:

```bash
DATASET_NAME=prof-ramos/JurDatasetBrasil
DATASET_VERSION=v0.1
ENABLE_ANALYTICS=true
```

---

## ðŸ” Monitoramento

### Logs do Space

```bash
# Via CLI
huggingface-cli logs prof-ramos/JurDatasetBrasil-Explorer

# Via UI
# Acesse: https://huggingface.co/spaces/prof-ramos/JurDatasetBrasil-Explorer
# Clique em "Logs" tab
```

### Analytics do Dataset

```bash
# EstatÃ­sticas de download
huggingface-cli stats prof-ramos/JurDatasetBrasil
```

---

## ðŸ› Troubleshooting

### Problema: Space nÃ£o inicia

**SoluÃ§Ã£o:**
```bash
# 1. Verificar logs
huggingface-cli logs prof-ramos/JurDatasetBrasil-Explorer

# 2. Verificar requirements
cat requirements-huggingface.txt

# 3. Testar localmente
docker build -f Dockerfile.huggingface -t test .
docker run -p 7860:7860 test
```

### Problema: Dataset nÃ£o aparece

**SoluÃ§Ã£o:**
```bash
# 1. Verificar se upload foi bem-sucedido
huggingface-cli list prof-ramos

# 2. Verificar permissÃµes
# Dataset deve estar pÃºblico ou vocÃª deve estar logado

# 3. ForÃ§ar refresh do cache
from datasets import load_dataset
dataset = load_dataset("prof-ramos/JurDatasetBrasil", download_mode="force_redownload")
```

### Problema: Token invÃ¡lido

**SoluÃ§Ã£o:**
```bash
# 1. Gerar novo token
# https://huggingface.co/settings/tokens

# 2. Atualizar GitHub Secret
# Settings â†’ Secrets â†’ Edit HF_TOKEN

# 3. Relogar localmente
huggingface-cli logout
huggingface-cli login
```

### Problema: Build timeout

**SoluÃ§Ã£o:**
```bash
# Reduzir dependÃªncias em requirements-huggingface.txt
# Remover pacotes nÃ£o usados
# Usar versÃµes especÃ­ficas (nÃ£o >=)
```

---

## ðŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o Oficial

- [HF Spaces Docs](https://huggingface.co/docs/hub/spaces)
- [HF Datasets Docs](https://huggingface.co/docs/datasets)
- [Gradio Docs](https://gradio.app/docs/)

### Templates

- [Gradio Space Template](https://huggingface.co/spaces/gradio/blocks-gallery)
- [Dataset Card Template](https://huggingface.co/docs/hub/datasets-cards)

### Exemplos

- [Dataset Browser](https://huggingface.co/spaces/huggingface/dataset-viewer)
- [Model Cards](https://huggingface.co/models?sort=trending)

---

## ðŸŽ¯ Checklist de Deploy

Antes de fazer deploy em produÃ§Ã£o:

- [ ] Token HF configurado no GitHub Secrets
- [ ] Dataset exportado para JSONL (`3-FinalDataset/`)
- [ ] README.md do dataset atualizado
- [ ] Space testado localmente
- [ ] CI/CD workflow testado
- [ ] PermissÃµes do dataset configuradas (pÃºblico/privado)
- [ ] Analytics habilitado (opcional)
- [ ] Custom domain configurado (opcional)

---

## ðŸš€ Quick Deploy Checklist

```bash
# 1. Setup inicial (uma vez)
huggingface-cli login
gh secret set HF_TOKEN

# 2. Preparar dataset
python scripts/run_pipeline.py
python scripts/05_export_to_jsonl.py

# 3. Upload dataset
python huggingface/upload_dataset.py

# 4. Deploy Space (automÃ¡tico via push)
git add huggingface/
git commit -m "feat: atualizar HF Space"
git push origin main

# 5. Verificar
open https://huggingface.co/spaces/prof-ramos/JurDatasetBrasil-Explorer
```

---

**Pronto para produÃ§Ã£o!** ðŸŽ‰

Se encontrar problemas, abra uma [issue no GitHub](https://github.com/prof-ramos/JurDatasetBrasil/issues).
