# JurDatasetBrasil - Variáveis de Ambiente
# Copie este arquivo para .env e preencha com suas credenciais

# =============================================================================
# SUPABASE
# =============================================================================
SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_KEY=sua-chave-anon-key-aqui
SUPABASE_SERVICE_ROLE_KEY=sua-service-role-key-aqui

# =============================================================================
# BANCO DE DADOS LOCAL (para docker-compose)
# =============================================================================
POSTGRES_DB=jurdataset
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_PORT=5432
# DATABASE_URL tem precedência sobre as variáveis acima
DATABASE_URL=postgresql://postgres:postgres@db:5432/jurdataset

# =============================================================================
# OPENROUTER (para Gemini e Grok)
# =============================================================================
OPENROUTER_API_KEY=sua-chave-openrouter-aqui

# Modelos disponíveis no OpenRouter
# Gemini 2.5 Flash: google/gemini-flash-1.5
# Grok 4.1 Fast: x-ai/grok-beta

# =============================================================================
# HUGGING FACE
# =============================================================================
# Token de acesso do Hugging Face (para uploads privados)
HF_TOKEN=sua-hf-token-aqui
# Nome do repositório no Hugging Face (ex: seu-usuario/jur-dataset-brasil)
HF_REPO=seu-usuario/jur-dataset-brasil
# Tipo de repositório (dataset ou model)
HF_REPO_TYPE=dataset

# =============================================================================
# EMBEDDINGS
# =============================================================================
# Modelo de embedding (padrão: sentence-transformers local)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Alternativa: OpenAI embeddings (requer OPENAI_API_KEY)
# EMBEDDING_MODEL=openai/text-embedding-3-small
# EMBEDDING_DIMENSION=1536

# Para o projeto, o ideal é usar embeddings de 1536 dimensões (conforme CLAUDE.md)
# Recomendação: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
# ou OpenAI text-embedding-3-small para melhor qualidade em português jurídico

# =============================================================================
# CONFIGURAÇÕES DO PIPELINE
# =============================================================================

# Chunking
CHUNK_SIZE=1500
CHUNK_OVERLAP=200

# Geração de exemplos
MAX_EXAMPLES_PER_CHUNK=3
GENERATION_BATCH_SIZE=10
TEMPERATURE=0.3

# Qualidade
MIN_OUTPUT_LENGTH=50
MAX_OUTPUT_LENGTH=1000
SIMILARITY_THRESHOLD=0.85

# =============================================================================
# DIRETÓRIOS
# =============================================================================
RAW_DOCS_DIR=0-RawDocs
MARKDOWN_DIR=1-MarkdownClean
CHUNKS_DIR=2-Chunks
DATASET_DIR=3-FinalDataset
BENCHMARKS_DIR=4-Benchmarks
MODELS_DIR=5-Models
LOGS_DIR=logs

# =============================================================================
# EXECUÇÃO
# =============================================================================
# Número de workers para processamento paralelo
NUM_WORKERS=4

# Delay entre requisições de API (em segundos)
API_DELAY=1.0

# Modo de execução (development, production)
ENV=development

# Ativar logs detalhados
DEBUG=True

# Portas dos serviços locais
API_PORT=8000
DASHBOARD_PORT=8501
